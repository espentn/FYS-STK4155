{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Franke Fumction\n",
    "def frankeFunction(x1,x2,sig2):\n",
    "    noise = np.random.normal(0,sig2,x1.shape)\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x1-2)**2) - 0.25*((9*x2-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x1+1)**2)/49.0 - 0.1*(9*x2+1))\n",
    "    term3 = 0.5*np.exp(-(9*x1-7)**2/4.0 - 0.25*((9*x2-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x1-4)**2 - (9*x2-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + noise\n",
    "\n",
    "# Create the data points in mesh grid form\n",
    "def createDataPoints(n, sig2):\n",
    "    x1 = np.arange(0, 1, 1/n)\n",
    "    x2 = np.arange(0, 1, 1/n)\n",
    "    x1_d, x2_d = np.meshgrid(x1,x2)\n",
    "    y_d = frankeFunction(x1_d,x2_d,sig2)\n",
    "    return x1_d, x2_d, y_d.ravel()\n",
    "\n",
    "@jit\n",
    "def createDesignMatrix(x1, x2, n=4):\n",
    "    if len(x1.shape) > 1:\n",
    "        x1 = np.ravel(x1)\n",
    "        x2 = np.ravel(x2)\n",
    "\n",
    "    N = len(x1)\n",
    "    p = int((n+1)*(n+2)/2)\n",
    "    X = np.ones((N,p))\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        q = int(i*(i+1)/2)\n",
    "        for j in range(i+1):\n",
    "            X[:,q+j] = (x1**(i-j))*(x2**j)\n",
    "    return X\n",
    "\n",
    "# The stochastic gradient descent method\n",
    "def SGD(X, y):\n",
    "    theta_linreg = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = [10^-4, 10^-3, 10^-2, 10^-1]\n",
    "numMiniBatch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def olsRegression(X_train,X_test,y_train,y_test, etas, numMiniBatch, CV):\n",
    "    \n",
    "    beta = np.random.normal(scale=0.1, X_train.shape[1])\n",
    "    \n",
    "    for i in range(NIterations):\n",
    "        gradients = 2.0/m*X_train.T @ ((X_train @ beta)-y)\n",
    "        beta -= eta*gradients\n",
    "\n",
    "    betaAna = np.linalg.pinv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "    y_tilde = (X_train @ beta)\n",
    "    y_pred = (X_test @ beta)\n",
    "\n",
    "    if CV == False:\n",
    "        print(f\"The R2 value for a polynomial of order {degree}, OLS test: {R2(y_test, y_pred)}\")\n",
    "        print(f\"The MSE value for a polynomial of order {degree}, OLS test: {MSE(y_test, y_pred)}\")\n",
    "        print(f\"\\nThe R2 value for a polynomial of order {degree}, OLS train: {R2(y_train, y_tilde)}\")\n",
    "        print(f\"The MSE value for a polynomial of order {degree}, OLS train: {MSE(y_train, y_tilde)}\")\n",
    "        \n",
    "    return beta, y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
