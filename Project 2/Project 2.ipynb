{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Franke Fumction\n",
    "def frankeFunction(x1,x2,sig2):\n",
    "    noise = np.random.normal(0,sig2,x1.shape)\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x1-2)**2) - 0.25*((9*x2-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x1+1)**2)/49.0 - 0.1*(9*x2+1))\n",
    "    term3 = 0.5*np.exp(-(9*x1-7)**2/4.0 - 0.25*((9*x2-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x1-4)**2 - (9*x2-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + noise\n",
    "\n",
    "# Create the data points in mesh grid form\n",
    "def createDataPoints(n, sig2):\n",
    "    x1 = np.arange(0, 1, 1/n)\n",
    "    x2 = np.arange(0, 1, 1/n)\n",
    "    x1_d, x2_d = np.meshgrid(x1,x2)\n",
    "    y_d = frankeFunction(x1_d,x2_d,sig2)\n",
    "    return x1_d, x2_d, y_d.ravel()\n",
    "\n",
    "@jit\n",
    "def createDesignMatrix(x1, x2, n=4):\n",
    "    if len(x1.shape) > 1:\n",
    "        x1 = np.ravel(x1)\n",
    "        x2 = np.ravel(x2)\n",
    "\n",
    "    N = len(x1)\n",
    "    p = int((n+1)*(n+2)/2)\n",
    "    X = np.ones((N,p))\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        q = int(i*(i+1)/2)\n",
    "        for j in range(i+1):\n",
    "            X[:,q+j] = (x1**(i-j))*(x2**j)\n",
    "    return X\n",
    "\n",
    "# Calculate the mean square error (MSE)\n",
    "def MSE(y_data, y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "# Calculate the coefficient of determination (R2)\n",
    "def R2(y_data, y_model):\n",
    "    n = np.size(y_data)\n",
    "    return 1 - np.sum((y_data-y_model)**2)/np.sum((y_data-(np.sum(y_data)/n))**2)\n",
    "\n",
    "def Scale(X_train, X_test):\n",
    "    XX = np.copy(X_test)\n",
    "    if X_train.shape[1] > 1:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train[:,1:])\n",
    "        X_train[:,1:] = scaler.transform(X_train[:,1:])\n",
    "        XX[:,1:] = scaler.transform(XX[:,1:])  \n",
    "    return X_train, XX#, y_train[:, np.newaxis], y_test[:, np.newaxis]\n",
    "\n",
    "\n",
    "# The stochastic gradient descent method\n",
    "def SGD(X, y):\n",
    "    theta_linreg = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = [10^-4, 10^-3, 10^-2, 10^-1]\n",
    "numMiniBatch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.9729194305382192\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.0020141301603733897\n",
      "\n",
      "The R2 value for a polynomial of order 5, Ana train: 0.9787329892861849\n",
      "The MSE value for a polynomial of order 5, Ana train: 0.001581743979207379\n",
      "[[ 0.44203531]\n",
      " [ 1.00705751]\n",
      " [ 0.51564604]\n",
      " [-3.88306348]\n",
      " [ 0.14270999]\n",
      " [-2.00838877]\n",
      " [ 1.86866122]\n",
      " [ 0.30614536]\n",
      " [-0.4468004 ]\n",
      " [ 0.58530821]\n",
      " [ 2.95268251]\n",
      " [-0.4624873 ]\n",
      " [ 2.64023932]\n",
      " [-1.71623163]\n",
      " [ 1.91770716]\n",
      " [-2.18391212]\n",
      " [-0.1136331 ]\n",
      " [-0.41839019]\n",
      " [-1.25037788]\n",
      " [ 1.39791477]\n",
      " [-1.19830279]]\n",
      "\n",
      "[[ 0.44203531]\n",
      " [ 1.24797588]\n",
      " [ 0.29523347]\n",
      " [-4.49953049]\n",
      " [-0.54424774]\n",
      " [ 0.10509059]\n",
      " [ 1.26031001]\n",
      " [ 2.61592339]\n",
      " [ 0.24034948]\n",
      " [-5.61627528]\n",
      " [ 5.34541355]\n",
      " [-3.44027975]\n",
      " [ 2.29726577]\n",
      " [-2.68369269]\n",
      " [ 9.27701219]\n",
      " [-3.59182501]\n",
      " [ 1.11703174]\n",
      " [-0.1657703 ]\n",
      " [-1.26348447]\n",
      " [ 1.89484826]\n",
      " [-4.23729917]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "sig2 = 0#.01 # noise variance\n",
    "degree = 5 # polynomial degree\n",
    "n = 10 # number of data points for each feature\n",
    "x1, x2, y = createDataPoints(n, sig2)\n",
    "X_train = createDesignMatrix(x1,x2,degree)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    "X_train, X_test = Scale(X_train, X_test)\n",
    "y_train = y_train[:, np.newaxis]\n",
    "\n",
    "m = X_train.shape[0] # number of training examples\n",
    "eta = 0.01\n",
    "NIterations = 2000000\n",
    "\n",
    "def olsRegression(X_train,X_test,y_train,y_test, etas, numMiniBatch, CV=True):\n",
    "    \n",
    "    beta = np.random.normal(scale=0.1, size=(X_train.shape[1],1))\n",
    "    \n",
    "    for i in range(NIterations):\n",
    "        gradients = 2.0/m*X_train.T @ ((X_train @ beta)-y_train)\n",
    "        beta -= eta*gradients\n",
    "\n",
    "    betaAna = np.linalg.pinv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "    y_tilde = (X_train @ beta)\n",
    "    y_ana = (X_train @ betaAna)\n",
    "    y_pred = (X_test @ beta)\n",
    "    if CV == True:\n",
    "#         print(f\"The R2 value for a polynomial of order {degree}, OLS test: {R2(y_test, y_pred)}\")\n",
    "#         print(f\"The MSE value for a polynomial of order {degree}, OLS test: {MSE(y_test, y_pred)}\")\n",
    "        print(f\"\\nThe R2 value for a polynomial of order {degree}, OLS train: {R2(y_train, y_tilde)}\")\n",
    "        print(f\"The MSE value for a polynomial of order {degree}, OLS train: {MSE(y_train, y_tilde)}\")\n",
    "        \n",
    "        print(f\"\\nThe R2 value for a polynomial of order {degree}, Ana train: {R2(y_train, y_ana)}\")\n",
    "        print(f\"The MSE value for a polynomial of order {degree}, Ana train: {MSE(y_train, y_ana)}\")\n",
    "        \n",
    "    print(beta)\n",
    "    print()\n",
    "    print(betaAna)\n",
    "    return beta, y_pred\n",
    "\n",
    "_, yy = olsRegression(X_train,X_test,y_train,y_test,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.9108586277315887\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.006629931718248028\n",
      "\n",
      "The R2 value for a polynomial of order 5, Ana train: 0.9787329892861849\n",
      "The MSE value for a polynomial of order 5, Ana train: 0.001581743979207379\n",
      "[[ 0.44188995]\n",
      " [ 0.13475272]\n",
      " [ 0.1960883 ]\n",
      " [-0.9056089 ]\n",
      " [ 0.20038305]\n",
      " [-0.80710424]\n",
      " [ 0.11261545]\n",
      " [ 0.13802502]\n",
      " [-0.16645109]\n",
      " [-0.08736562]\n",
      " [ 0.52980591]\n",
      " [ 0.29866148]\n",
      " [ 0.08891222]\n",
      " [-0.18540487]\n",
      " [ 0.29692551]\n",
      " [-0.14036431]\n",
      " [-0.34555878]\n",
      " [ 0.05127774]\n",
      " [-0.0237595 ]\n",
      " [ 0.07248473]\n",
      " [ 0.19269134]]\n",
      "\n",
      "[[ 0.44203531]\n",
      " [ 1.24797588]\n",
      " [ 0.29523347]\n",
      " [-4.49953049]\n",
      " [-0.54424774]\n",
      " [ 0.10509059]\n",
      " [ 1.26031001]\n",
      " [ 2.61592339]\n",
      " [ 0.24034948]\n",
      " [-5.61627528]\n",
      " [ 5.34541355]\n",
      " [-3.44027975]\n",
      " [ 2.29726577]\n",
      " [-2.68369269]\n",
      " [ 9.27701219]\n",
      " [-3.59182501]\n",
      " [ 1.11703174]\n",
      " [-0.1657703 ]\n",
      " [-1.26348447]\n",
      " [ 1.89484826]\n",
      " [-4.23729917]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "sig2 = 0#.01 # noise variance\n",
    "degree = 5 # polynomial degree\n",
    "n = 10 # number of data points for each feature\n",
    "x1, x2, y = createDataPoints(n, sig2)\n",
    "X_train = createDesignMatrix(x1,x2,degree)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    "X_train, X_test = Scale(X_train, X_test)\n",
    "y_train = y_train[:, np.newaxis]\n",
    "\n",
    "m = X_train.shape[0] # number of training examples\n",
    "samPerMini = 7\n",
    "numMiniBatch = np.int(m/samPerMini)\n",
    "eta = 0.01\n",
    "    \n",
    "n_epochs = 1000\n",
    "t0, t1 = 5, 50\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "def momentumSGD(beta):\n",
    "    gamma = 0.9\n",
    "    velocity = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(numMiniBatch):\n",
    "#             random_index = np.random.randint(m)\n",
    "#             xi = X_train[random_index:random_index+1]\n",
    "#             yi = y_train[random_index:random_index+1]\n",
    "\n",
    "            xi = X_train[i*samPerMini:(i+1)*samPerMini]\n",
    "#             print(\"xi\",xi.shape)\n",
    "            yi = y_train[i*samPerMini:(i+1)*samPerMini]\n",
    "#             print(\"yi\",yi.shape)\n",
    "            \n",
    "            gradients = 2 * xi.T @ ((xi @ beta)-yi)\n",
    "            velocity = gamma*velocity + (1-gamma)*gradients\n",
    "    #             eta = learning_schedule(epoch*m+i)\n",
    "            beta = beta - eta*velocity\n",
    "    return beta\n",
    "\n",
    "def olsRegression(X_train,X_test,y_train,y_test, etas, numMiniBatch, CV=True):\n",
    "    \n",
    "    beta = np.random.normal(scale=0.1, size=(X_train.shape[1],1))\n",
    "\n",
    "    beta = momentumSGD(beta)\n",
    "    \n",
    "    betaAna = np.linalg.pinv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "    y_tilde = (X_train @ beta)\n",
    "    y_ana = (X_train @ betaAna)\n",
    "    y_pred = (X_test @ beta)\n",
    "    if CV == True:\n",
    "#         print(f\"The R2 value for a polynomial of order {degree}, OLS test: {R2(y_test, y_pred)}\")\n",
    "#         print(f\"The MSE value for a polynomial of order {degree}, OLS test: {MSE(y_test, y_pred)}\")\n",
    "        print(f\"\\nThe R2 value for a polynomial of order {degree}, OLS train: {R2(y_train, y_tilde)}\")\n",
    "        print(f\"The MSE value for a polynomial of order {degree}, OLS train: {MSE(y_train, y_tilde)}\")\n",
    "        \n",
    "        print(f\"\\nThe R2 value for a polynomial of order {degree}, Ana train: {R2(y_train, y_ana)}\")\n",
    "        print(f\"The MSE value for a polynomial of order {degree}, Ana train: {MSE(y_train, y_ana)}\")\n",
    "        \n",
    "    print(beta)\n",
    "    print()\n",
    "    print(betaAna)\n",
    "    return beta, y_pred\n",
    "\n",
    "_, yy = olsRegression(X_train,X_test,y_train,y_test,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
