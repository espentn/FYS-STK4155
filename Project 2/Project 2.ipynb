{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Franke Fumction\n",
    "def frankeFunction(x1,x2,sig2):\n",
    "    noise = np.random.normal(0,sig2,x1.shape)\n",
    "    term1 = 0.75*np.exp(-(0.25*(9*x1-2)**2) - 0.25*((9*x2-2)**2))\n",
    "    term2 = 0.75*np.exp(-((9*x1+1)**2)/49.0 - 0.1*(9*x2+1))\n",
    "    term3 = 0.5*np.exp(-(9*x1-7)**2/4.0 - 0.25*((9*x2-3)**2))\n",
    "    term4 = -0.2*np.exp(-(9*x1-4)**2 - (9*x2-7)**2)\n",
    "    return term1 + term2 + term3 + term4 + noise\n",
    "\n",
    "# Create the data points in mesh grid form\n",
    "def createDataPoints(n, sig2):\n",
    "    x1 = np.arange(0, 1, 1/n)\n",
    "    x2 = np.arange(0, 1, 1/n)\n",
    "    x1_d, x2_d = np.meshgrid(x1,x2)\n",
    "    y_d = frankeFunction(x1_d,x2_d,sig2)\n",
    "    return x1_d, x2_d, y_d.ravel()\n",
    "\n",
    "@jit\n",
    "def createDesignMatrix(x1, x2, n=4):\n",
    "    if len(x1.shape) > 1:\n",
    "        x1 = np.ravel(x1)\n",
    "        x2 = np.ravel(x2)\n",
    "\n",
    "    N = len(x1)\n",
    "    p = int((n+1)*(n+2)/2)\n",
    "    X = np.ones((N,p))\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        q = int(i*(i+1)/2)\n",
    "        for j in range(i+1):\n",
    "            X[:,q+j] = (x1**(i-j))*(x2**j)\n",
    "    return X\n",
    "\n",
    "# Calculate the mean square error (MSE)\n",
    "def MSE(y_data, y_model):\n",
    "    n = np.size(y_model)\n",
    "    return np.sum((y_data-y_model)**2)/n\n",
    "\n",
    "# Calculate the coefficient of determination (R2)\n",
    "def R2(y_data, y_model):\n",
    "    n = np.size(y_data)\n",
    "    return 1 - np.sum((y_data-y_model)**2)/np.sum((y_data-(np.sum(y_data)/n))**2)\n",
    "\n",
    "def Scale(X_train, X_test):\n",
    "    XX = np.copy(X_test)\n",
    "    if X_train.shape[1] > 1:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train[:,1:])\n",
    "        X_train[:,1:] = scaler.transform(X_train[:,1:])\n",
    "        XX[:,1:] = scaler.transform(XX[:,1:])  \n",
    "    return X_train, XX#, y_train[:, np.newaxis], y_test[:, np.newaxis]\n",
    "\n",
    "\n",
    "# The stochastic gradient descent method\n",
    "def SGD(X, y):\n",
    "    theta_linreg = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta 0.0001\n",
      "sam 1\n",
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.8841448654678465\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.009215886028819365\n",
      "sam 4\n",
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.8724018571651226\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.010150002816913447\n",
      "sam 8\n",
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.845568144932382\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.012284534313214468\n",
      "sam 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-73c5d00185f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0molsRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamPerMini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-73c5d00185f3>\u001b[0m in \u001b[0;36molsRegression\u001b[0;34m(X_train, X_test, y_train, y_test, n_epochs, samPerMini, etas)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamPerMini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmomentumSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msamPerMini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamPerMini\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mbetaAna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-73c5d00185f3>\u001b[0m in \u001b[0;36mmomentumSGD\u001b[0;34m(beta, n_epochs, numMiniBatch, samPerMini, eta)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamPerMini\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamPerMini\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msamPerMini\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mvelocity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvelocity\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#             eta = learning_schedule(epoch*m+i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "sig2 = 0#.01 # noise variance\n",
    "degree = 5 # polynomial degree\n",
    "n = 16 # number of data points for each feature\n",
    "\n",
    "x1, x2, y = createDataPoints(n, sig2)\n",
    "X = createDesignMatrix(x1,x2,degree)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "X_train, X_test = Scale(X_train, X_test)\n",
    "y_train = y_train[:, np.newaxis]\n",
    "\n",
    "m = X_train.shape[0] # number of training examples\n",
    "samPerMini = [1, 4, 8, 16] # number of samples per mini-batch    \n",
    "etas = [1E-4, 1E-3, 1E-2, 5E-2] # learning rates to use\n",
    "    \n",
    "n_epochs = 10000 # number of epochs\n",
    "t0, t1 = 5, 50\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "def momentumSGD(beta, n_epochs, numMiniBatch, samPerMini, eta):\n",
    "    gamma = 0.9\n",
    "    velocity = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(numMiniBatch):\n",
    "\n",
    "            xi = X_train[i*samPerMini:(i+1)*samPerMini]\n",
    "            yi = y_train[i*samPerMini:(i+1)*samPerMini]\n",
    "            \n",
    "            gradients = 2/samPerMini * xi.T @ ((xi @ beta)-yi)\n",
    "            velocity = gamma*velocity + (1-gamma)*gradients\n",
    "#             eta = learning_schedule(epoch*m+i)\n",
    "            beta = beta - eta*velocity\n",
    "    return beta\n",
    "\n",
    "def olsRegression(X_train,X_test,y_train,y_test, n_epochs, samPerMini, etas):\n",
    "    \n",
    "    for eta in etas:\n",
    "        print(\"eta\", eta)\n",
    "        for i in range(len(samPerMini)):\n",
    "            print(\"sam\", samPerMini[i])\n",
    "            beta = np.random.normal(scale=0.1, size=(X_train.shape[1],1))\n",
    "            beta = momentumSGD(beta, n_epochs, np.int(m/samPerMini[i]), samPerMini[i], eta)\n",
    "\n",
    "            betaAna = np.linalg.pinv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "            y_tilde = (X_train @ beta)\n",
    "            y_ana = (X_train @ betaAna)\n",
    "            y_pred = (X_test @ beta)\n",
    "\n",
    "        #     print(f\"The R2 value for a polynomial of order {degree}, OLS test: {R2(y_test, y_pred)}\")\n",
    "        #     print(f\"The MSE value for a polynomial of order {degree}, OLS test: {MSE(y_test, y_pred)}\")\n",
    "            print(f\"\\nThe R2 value for a polynomial of order {degree}, OLS train: {R2(y_train, y_tilde)}\")\n",
    "            print(f\"The MSE value for a polynomial of order {degree}, OLS train: {MSE(y_train, y_tilde)}\")\n",
    "\n",
    "#             print(f\"\\nThe R2 value for a polynomial of order {degree}, Ana train: {R2(y_train, y_ana)}\")\n",
    "#             print(f\"The MSE value for a polynomial of order {degree}, Ana train: {MSE(y_train, y_ana)}\")\n",
    "\n",
    "    return beta, y_pred\n",
    "\n",
    "_, yy = olsRegression(X_train,X_test,y_train,y_test,n_epochs, samPerMini, etas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta 0.0001\n",
      "sam 4\n",
      "0.0001\n",
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.8638910307836747\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.010827010411434218\n",
      "0.001\n",
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.8720339884550596\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.010179265534696297\n",
      "0.01\n",
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.8647571802134268\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.010758111139418713\n",
      "0.05\n",
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.8498251374806491\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.01194590488337702\n",
      "eta 0.001\n",
      "sam 4\n",
      "0.0001\n",
      "\n",
      "The R2 value for a polynomial of order 5, OLS train: 0.9027796702252523\n",
      "The MSE value for a polynomial of order 5, OLS train: 0.007733550027855245\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "sig2 = 0#.01 # noise variance\n",
    "degree = 5 # polynomial degree\n",
    "n = 16 # number of data points for each feature\n",
    "\n",
    "x1, x2, y = createDataPoints(n, sig2)\n",
    "X = createDesignMatrix(x1,x2,degree)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "X_train, X_test = Scale(X_train, X_test)\n",
    "y_train = y_train[:, np.newaxis]\n",
    "\n",
    "m = X_train.shape[0] # number of training examples\n",
    "samPerMini = [4] # number of samples per mini-batch    \n",
    "etas = [1E-4, 1E-3, 1E-2, 5E-2] # learning rates to use\n",
    "lmbs = [1E-4, 1E-3, 1E-2, 5E-2]    \n",
    "    \n",
    "n_epochs = 10000 # number of epochs\n",
    "t0, t1 = 5, 50\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "def momentumSGD(beta, n_epochs, numMiniBatch, samPerMini, eta, lmb):\n",
    "    gamma = 0.9\n",
    "    velocity = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(numMiniBatch):\n",
    "\n",
    "            xi = X_train[i*samPerMini:(i+1)*samPerMini]\n",
    "            yi = y_train[i*samPerMini:(i+1)*samPerMini]\n",
    "            \n",
    "            gradients = 2/samPerMini * (xi.T @ ((xi @ beta)-yi) + lmb * beta)\n",
    "            velocity = gamma*velocity + (1-gamma)*gradients\n",
    "#             eta = learning_schedule(epoch*m+i)\n",
    "            beta = beta - eta*velocity\n",
    "    return beta\n",
    "\n",
    "def ridgeRegression(X_train,X_test,y_train,y_test, n_epochs, samPerMini, etas):\n",
    "    \n",
    "    for eta in etas:\n",
    "        print(\"eta\", eta)\n",
    "        for i in range(len(samPerMini)):\n",
    "            print(\"sam\", samPerMini[i])\n",
    "            for lmb in lmbs:\n",
    "                print(lmb)\n",
    "                beta = np.random.normal(scale=0.1, size=(X_train.shape[1],1))\n",
    "                beta = momentumSGD(beta, n_epochs, np.int(m/samPerMini[i]), samPerMini[i], eta, lmb)\n",
    "\n",
    "                betaAna = np.linalg.pinv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
    "                y_tilde = (X_train @ beta)\n",
    "                y_ana = (X_train @ betaAna)\n",
    "                y_pred = (X_test @ beta)\n",
    "\n",
    "            #     print(f\"The R2 value for a polynomial of order {degree}, OLS test: {R2(y_test, y_pred)}\")\n",
    "            #     print(f\"The MSE value for a polynomial of order {degree}, OLS test: {MSE(y_test, y_pred)}\")\n",
    "                print(f\"\\nThe R2 value for a polynomial of order {degree}, OLS train: {R2(y_train, y_tilde)}\")\n",
    "                print(f\"The MSE value for a polynomial of order {degree}, OLS train: {MSE(y_train, y_tilde)}\")\n",
    "\n",
    "    #             print(f\"\\nThe R2 value for a polynomial of order {degree}, Ana train: {R2(y_train, y_ana)}\")\n",
    "    #             print(f\"The MSE value for a polynomial of order {degree}, Ana train: {MSE(y_train, y_ana)}\")\n",
    "\n",
    "    return beta, y_pred\n",
    "\n",
    "_, yy = ridgeRegression(X_train,X_test,y_train,y_test,n_epochs, samPerMini, etas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
